{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23da1039-b4d3-4da2-9482-b289e4240e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg corr(pred rating, true rating) for each quintile of type frequency (E[T]) for full model and reports only model on semisynthetic data\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Set the font used for math expressions to LaTeX\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae437b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "base_file = '/share/garg/311_data/sb2377/clean_codebase/three_year_base.csv'\n",
    "results_dir = '/share/garg/311_data/sb2377/results'\n",
    "\n",
    "# user specified arguments\n",
    "types = {'Street': 'StreetConditionDOT',\n",
    "         'Park': 'MaintenanceorFacilityDPR',\n",
    "         'Rodent': 'RodentDOHMH',\n",
    "         'Food': 'FoodDOHMH',\n",
    "         'DCWP': 'ConsumerComplaintDCWP'}\n",
    "models = {'Full model': {'job_ids':[i * 3 + 3200 for i in range(20)]},\n",
    "          'Reports-only model': {'job_ids':[i * 3 + 3201 for i in range(20)]}}\n",
    "epoch = '59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7988dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "base_df = pd.read_csv(base_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d12e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get type indices\n",
    "# for df with all types\n",
    "type_df = base_df[['typeagency', 'type_idxs']].drop_duplicates()\n",
    "indices = {}\n",
    "for type_name, type_id in types.items():\n",
    "    idx = type_df[type_df['typeagency'] == type_id]['type_idxs'].iloc[0]\n",
    "    indices[type_name] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ee3233-b61b-46f5-948f-e91d5a46cb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model: checkpoint files done = 20\n",
      "Full model: results files done = 20\n",
      "Reports-only model: checkpoint files done = 20\n",
      "Reports-only model: results files done = 20\n"
     ]
    }
   ],
   "source": [
    "# get predicted ratings for all jobs\n",
    "checkpoint_file = '{}/job{}/model-epoch={}.ckpt'\n",
    "results_file = '{}/job{}/epoch={}_test_unobserved.pkl'\n",
    "checkpoint_counters = {}\n",
    "results_counters = {}\n",
    "for m in models:\n",
    "    checkpoint_counters[m] = 0\n",
    "    results_counters[m] = 0\n",
    "dfs = {}\n",
    "for m in models:\n",
    "    dfs[m] = []\n",
    "\n",
    "for m in models:\n",
    "    for i, job_idx in enumerate(models[m]['job_ids']):\n",
    "        if os.path.exists(checkpoint_file.format(results_dir, job_idx, epoch)):\n",
    "            checkpoint_counters[m] += 1\n",
    "        if os.path.exists(results_file.format(results_dir, job_idx, epoch)):\n",
    "            results_counters[m] += 1\n",
    "            with open(results_file.format(results_dir, job_idx, epoch), 'rb') as file:\n",
    "                pred_rating, true_rating, mask, node_embedding, type_embedding, node_idxs, type_idxs, demographics, pred_pt, true_t = pickle.load(file)\n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            df['pred_rating'] = pred_rating\n",
    "            df['true_rating'] = true_rating\n",
    "            df['node_idxs'] = node_idxs\n",
    "            df['type_idxs'] = type_idxs\n",
    "            df['pred_pt'] = pred_pt\n",
    "            df['true_t'] = true_t\n",
    "            df['mask'] = mask\n",
    "            df['job_id'] = i\n",
    "\n",
    "            dfs[m].append(df)\n",
    "\n",
    "for m in models:\n",
    "    print('{}: checkpoint files done = {}'.format(m, checkpoint_counters[m]))\n",
    "    print('{}: results files done = {}'.format(m, results_counters[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d26274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Full model, Quintile 0-20%, Corr: 0.26891619090191043 \\pm 0.025082469820980446\n",
      "Model: Full model, Quintile 20-40%, Corr: 0.19731850839534595 \\pm 0.020658027588664418\n",
      "Model: Full model, Quintile 40-60%, Corr: 0.3667753357311248 \\pm 0.010829055778879635\n",
      "Model: Full model, Quintile 60-80%, Corr: 0.6020162966509004 \\pm 0.004915444233865695\n",
      "Model: Full model, Quintile 80-100%, Corr: 0.7677887792568437 \\pm 0.0022427212146255474\n",
      "Model: Reports-only model, Quintile 0-20%, Corr: -0.07395683401514073 \\pm 0.0352895001215662\n",
      "Model: Reports-only model, Quintile 20-40%, Corr: -0.0657438980919717 \\pm 0.02067375953093559\n",
      "Model: Reports-only model, Quintile 40-60%, Corr: 0.32649365290354904 \\pm 0.007284297465675729\n",
      "Model: Reports-only model, Quintile 60-80%, Corr: 0.5813738487305552 \\pm 0.004090901616726463\n",
      "Model: Reports-only model, Quintile 80-100%, Corr: 0.7451271065725565 \\pm 0.0022190179756350565\n"
     ]
    }
   ],
   "source": [
    "# print avg correlation for each qunitile of type frequency\n",
    "for m in models:\n",
    "    df_set = dfs[m]\n",
    "    corrs = []\n",
    "    freqs = []\n",
    "    for idx in range(len(dfs[m][0]['type_idxs'].unique())):\n",
    "        if idx not in list(indices.values()):\n",
    "            type_corrs = []\n",
    "            type_rmses = []\n",
    "            type_freqs = []\n",
    "            for df in df_set:\n",
    "                df_type = df[df['type_idxs'] == idx]\n",
    "                node_df = df_type.groupby(['node_idxs', 'type_idxs']).mean().reset_index()\n",
    "\n",
    "                # calculate correlation\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    if m == 'Reports-only model':\n",
    "                        # for reports-only model, we use -P(T) as a proxy for r\n",
    "                        corr = pearsonr(-1 * node_df['pred_pt'], node_df['true_rating'])\n",
    "                    else:\n",
    "                        corr = pearsonr(node_df['pred_rating'], node_df['true_rating'])\n",
    "                type_corrs.append(corr[0])\n",
    "\n",
    "                # calculate type frequency\n",
    "                type_freqs.append(df_type['true_t'].mean())\n",
    "\n",
    "            corrs.append(type_corrs)\n",
    "            freqs.append(type_freqs)\n",
    "\n",
    "    corrs = np.array(corrs)\n",
    "    freqs = np.array(freqs)\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['type_freq'] = freqs[:, 0]\n",
    "    for i in range(corrs.shape[1]):\n",
    "        results_df['corrs_{}'.format(i)] = corrs[:, i]\n",
    "    # Create quintiles for column type frequency\n",
    "    results_df['quintile'] = pd.qcut(results_df['type_freq'], q=5, labels=False) + 1  # Labels from 1 to 5\n",
    "    results_df.drop(columns=['type_freq'], inplace=True)\n",
    "\n",
    "    # Compute the average correlation of each type for each quintile\n",
    "    avg_per_quintile = results_df.groupby('quintile').mean()\n",
    "    avg_per_quintile = avg_per_quintile.to_numpy()\n",
    "    mean_avg_per_quintile = avg_per_quintile.mean(axis=1)\n",
    "\n",
    "    # Compute 95% CIs\n",
    "    std_per_quintile = avg_per_quintile.std(axis=1)\n",
    "    ci_per_quintile = 1.96 * std_per_quintile / np.sqrt(avg_per_quintile.shape[1] - 1)\n",
    "\n",
    "    for i in range(5):\n",
    "        print('Model: {}, Quintile {}-{}%, Corr: {} \\pm {}'.format(m, \n",
    "                                                                    i*20, \n",
    "                                                                    (i+1)*20, \n",
    "                                                                    mean_avg_per_quintile[i], \n",
    "                                                                    ci_per_quintile[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d0992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
